{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rit-ctrl/Pytorch-repo/blob/main/Pytorch-step-by-step/Chap_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3kCE72TojBV"
      },
      "source": [
        "Chapter 1 - Linear regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GmNqrhnPspc",
        "outputId": "d2028db0-f3c3-4ef9-f53f-0dee52ae086c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.12.0+cu113)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.1.1)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4150 sha256=9a35932eb4fa1e27563ddd986343367b70bfb9d0b148085eff9cf3b2410a65b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/38/f5/dc4f85c3909051823df49901e72015d2d750bd26b086480ec2\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchviz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QwH1k9YIoo10"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIZFcYLtQCB1"
      },
      "source": [
        "## Data Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uQftLU3OopVH"
      },
      "outputs": [],
      "source": [
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "# Data Generation\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(N, 1)\n",
        "epsilon = (.1 * np.random.randn(N, 1))\n",
        "y = true_b + true_w * x + epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "9jSgl3i4QH3d"
      },
      "outputs": [],
      "source": [
        "idx = np.arange(N)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:int(N*.8)]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[int(N*.8):]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "n_e3R9IWQlz2"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "F127X5OsQuLJ",
        "outputId": "7d2aa4da-a909-45d3-b00e-eb2c88eabc3e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc81607a490>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(x_train,y_train) #training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "IzgpoHw9Qwrn",
        "outputId": "c1d7e1b9-f6b9-4fa7-dfc4-107bb2fb43e7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fc815873f10>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.scatter(x_val,y_val) # val data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N58aUtjqRALS"
      },
      "source": [
        "## Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9Zw9740Q8X0",
        "outputId": "681afcc8-778f-4554-930c-934bf691b9bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.49671415] [-0.1382643]\n"
          ]
        }
      ],
      "source": [
        "# Step 0 - Random initialization of weights\n",
        "\n",
        "np.random.seed(42)\n",
        "b = np.random.randn(1)\n",
        "w = np.random.randn(1)\n",
        "\n",
        "print(b, w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "vVc1QKwFRUxI"
      },
      "outputs": [],
      "source": [
        "yhat = w*x_train + b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hr352YUsSXDL",
        "outputId": "6ac6838e-bc2d-49dd-e5c8-51e1b057b9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.7421577700550976\n"
          ]
        }
      ],
      "source": [
        "error = (yhat - y_train)\n",
        "\n",
        "# It is a regression, so it computes mean squared error (MSE)\n",
        "loss = (error ** 2).mean()\n",
        "\n",
        "print(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9E0kZ0IhS2wq"
      },
      "source": [
        "Computing gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55SErFlYSpKP",
        "outputId": "47cf487d-ae8e-4787-a2bc-a81ba6126be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-3.044811379650508 -1.8337537171510832\n"
          ]
        }
      ],
      "source": [
        "b_grad = 2 * error.mean()\n",
        "w_grad = 2 * (x_train * error).mean()\n",
        "print(b_grad, w_grad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81uQCOXS4y1",
        "outputId": "d6e4bc3e-bfa9-4b2d-b762-745d96753cf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.49671415] [-0.1382643]\n",
            "[0.80119529] [0.04511107]\n"
          ]
        }
      ],
      "source": [
        "lr = 0.1\n",
        "print(b, w)\n",
        "\n",
        "# Step 4 - Updates parameters using gradients and\n",
        "# the learning rate\n",
        "b = b - lr * b_grad\n",
        "w = w - lr * w_grad\n",
        "\n",
        "print(b, w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LxLkeeVS-m5",
        "outputId": "76e21b3c-5800-46e0-c14f-8dae6d48e82c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.49671415] [-0.1382643]\n",
            "[1.02354094] [1.96896411]\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(42)\n",
        "b = np.random.randn(1)\n",
        "w = np.random.randn(1)\n",
        "\n",
        "print(b, w)\n",
        "\n",
        "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
        "lr = 0.1\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Step 1 - Computes model's predicted output - forward pass\n",
        "    yhat = b + w * x_train\n",
        "    \n",
        "    # Step 2 - Computes the loss\n",
        "    # We are using ALL data points, so this is BATCH gradient\n",
        "    # descent. How wrong is our model? That's the error!   \n",
        "    error = (yhat - y_train)\n",
        "    # It is a regression, so it computes mean squared error (MSE)\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "    b_grad = 2 * error.mean()\n",
        "    w_grad = 2 * (x_train * error).mean()\n",
        "    \n",
        "    # Step 4 - Updates parameters using gradients and \n",
        "    # the learning rate\n",
        "    b = b - lr * b_grad\n",
        "    w = w - lr * w_grad\n",
        "    \n",
        "print(b, w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-_LaaGOW0sT",
        "outputId": "cc0ab874-4e44-45e5-a5f3-d68912026d12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.02354075] [1.96896447]\n"
          ]
        }
      ],
      "source": [
        "linr = LinearRegression()\n",
        "linr.fit(x_train, y_train)\n",
        "print(linr.intercept_, linr.coef_[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NL8RPRl0ZDSn"
      },
      "source": [
        "## Pytorch basics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zo6cVGnW8e8",
        "outputId": "7b45283f-0dc1-40a0-ab10-52cf28f0d37d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.float64"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "x_train_tensor.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgeII4rGZLLE",
        "outputId": "c27b4bbf-00bb-49b7-8514-496183ef133b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 3])"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dummy_array = np.array([1, 2, 3])\n",
        "dummy_tensor = torch.as_tensor(dummy_array)\n",
        "# Modifies the numpy array\n",
        "dummy_array[1] = 0\n",
        "# Tensor gets modified too...\n",
        "dummy_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "kz3xDceKbCSq",
        "outputId": "13fdd877-0300-42ea-d040-3f7c448eb641"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'cpu'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "L3HpLozgbRfe"
      },
      "outputs": [],
      "source": [
        "n_cudas = torch.cuda.device_count()\n",
        "for i in range(n_cudas):\n",
        "  print(torch.cuda.get_device_name(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJGryuorbeLm",
        "outputId": "79939491-78bd-4d07-c092-a82f417db47d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.0636], dtype=torch.float64)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gpu_tensor = torch.as_tensor(x_train).to(device)\n",
        "gpu_tensor[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIavbUe4bze2"
      },
      "source": [
        "## Using Pytorch to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "84zY5_bfbqe0"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Our data was in Numpy arrays, but we need to transform them\n",
        "# into PyTorch's Tensors and then we send them to the\n",
        "# chosen device\n",
        "\n",
        "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).float().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8KJqSdCb6j7",
        "outputId": "cee9e306-057e-41f1-e1ed-edeb06ace841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.FloatTensor\n"
          ]
        }
      ],
      "source": [
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "2fMcter8b-kz"
      },
      "outputs": [],
      "source": [
        "#use .cpu to convert to cpu tensor as numpy can't handle gpu tensor\n",
        "back_to_numpy = x_train_tensor.cpu().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nh3JjIFjcRig",
        "outputId": "6d80986c-7021-4134-cfdd-eb89aa116dec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([0.3367], requires_grad=True) tensor([0.1288], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "b = torch.randn(1, requires_grad=True, \\\n",
        "dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, \\\n",
        "dtype=torch.float, device=device)\n",
        "print(b, w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "7LhvpNlqlneL",
        "outputId": "c0f0bd1a-e6c7-4902-cc11-f21e0647ca6d"
      },
      "outputs": [
        {
          "data": {
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"222pt\" height=\"283pt\"\n viewBox=\"0.00 0.00 222.00 283.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 279)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-279 218,-279 218,4 -4,4\"/>\n<!-- 140497215264144 -->\n<g id=\"node1\" class=\"node\">\n<title>140497215264144</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"139,-31 74,-31 74,0 139,0 139,-31\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (80, 1)</text>\n</g>\n<!-- 140497215190416 -->\n<g id=\"node2\" class=\"node\">\n<title>140497215190416</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"151,-86 62,-86 62,-67 151,-67 151,-86\"/>\n<text text-anchor=\"middle\" x=\"106.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 140497215190416&#45;&gt;140497215264144 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140497215190416&#45;&gt;140497215264144</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M106.5,-66.9688C106.5,-60.1289 106.5,-50.5621 106.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"110.0001,-41.3678 106.5,-31.3678 103.0001,-41.3678 110.0001,-41.3678\"/>\n</g>\n<!-- 140497215190096 -->\n<g id=\"node3\" class=\"node\">\n<title>140497215190096</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-141 0,-141 0,-122 101,-122 101,-141\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140497215190096&#45;&gt;140497215190416 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140497215190096&#45;&gt;140497215190416</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M60.2545,-121.9197C68.1865,-114.1293 79.5788,-102.9405 89.0712,-93.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"91.7982,-95.845 96.4802,-86.3408 86.8932,-90.8509 91.7982,-95.845\"/>\n</g>\n<!-- 140497215263856 -->\n<g id=\"node4\" class=\"node\">\n<title>140497215263856</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"77.5,-208 23.5,-208 23.5,-177 77.5,-177 77.5,-208\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140497215263856&#45;&gt;140497215190096 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140497215263856&#45;&gt;140497215190096</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-176.791C50.5,-169.0249 50.5,-159.5706 50.5,-151.3129\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-151.0647 50.5,-141.0648 47.0001,-151.0648 54.0001,-151.0647\"/>\n</g>\n<!-- 140497215190800 -->\n<g id=\"node5\" class=\"node\">\n<title>140497215190800</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"208,-141 119,-141 119,-122 208,-122 208,-141\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 140497215190800&#45;&gt;140497215190416 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140497215190800&#45;&gt;140497215190416</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M153.5714,-121.9197C145.4169,-114.0514 133.6697,-102.7164 123.9508,-93.3385\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"126.3252,-90.7659 116.6987,-86.3408 121.4646,-95.8032 126.3252,-90.7659\"/>\n</g>\n<!-- 140497215192272 -->\n<g id=\"node6\" class=\"node\">\n<title>140497215192272</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"214,-202 113,-202 113,-183 214,-183 214,-202\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-190\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140497215192272&#45;&gt;140497215190800 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140497215192272&#45;&gt;140497215190800</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-182.9688C163.5,-174.5131 163.5,-161.8901 163.5,-151.2615\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-151.1656 163.5,-141.1656 160.0001,-151.1657 167.0001,-151.1656\"/>\n</g>\n<!-- 140497215265008 -->\n<g id=\"node7\" class=\"node\">\n<title>140497215265008</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"190.5,-275 136.5,-275 136.5,-244 190.5,-244 190.5,-275\"/>\n<text text-anchor=\"middle\" x=\"163.5\" y=\"-251\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 140497215265008&#45;&gt;140497215192272 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140497215265008&#45;&gt;140497215192272</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M163.5,-243.9604C163.5,-234.6356 163.5,-222.6748 163.5,-212.6317\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"167.0001,-212.35 163.5,-202.3501 160.0001,-212.3501 167.0001,-212.35\"/>\n</g>\n</g>\n</svg>\n",
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7fc80e9a7310>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "b = torch.randn(1, requires_grad=True, \\\n",
        "dtype=torch.float, device=device)\n",
        "w = torch.randn(1, requires_grad=True, \\\n",
        "dtype=torch.float, device=device)\n",
        "# Step 1 - Computes our model's predicted output - forward pass\n",
        "yhat = b + w * x_train_tensor\n",
        "# Step 2 - Computes the loss\n",
        "error = (yhat - y_train_tensor)\n",
        "loss = (error ** 2).mean()\n",
        "# We can try plotting the graph for any python variable:\n",
        "# yhat, error, loss...\n",
        "make_dot(yhat)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rEPsXi92oLlx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfc2lzB6pHnf"
      },
      "source": [
        "Using optim and loss fn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4iMAjsFepJ8J",
        "outputId": "bcb1097c-95cb-481c-9179-1ea547c9b9ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([1.1566], requires_grad=True) tensor([1.7086], requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "lr = 0.01\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "b = torch.randn(1,requires_grad=True,dtype = torch.float,device = device)\n",
        "w = torch.randn(1,requires_grad=True,dtype = torch.float,device = device)\n",
        "\n",
        "optimizer = optim.SGD([b,w],lr = lr)\n",
        "\n",
        "loss_fn = nn.MSELoss(reduction = 'mean')\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "  yhat = w*x_train_tensor + b\n",
        "\n",
        "  loss = loss_fn(yhat,y_train_tensor)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "print(b,w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBEbhjmzqLR3",
        "outputId": "5fcfe7da-ed8e-47b1-cbcc-f98d85f66537"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(0.0145, grad_fn=<MseLossBackward0>)"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y1CwwsKtqYAy",
        "outputId": "378e95bf-7900-49cf-e0b5-32fa4cc5956c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.1565992832183838 1 1.7086076736450195 2\n"
          ]
        }
      ],
      "source": [
        "print(b.item(),true_b,w.item(),true_w)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jFP2E3nfqckV",
        "outputId": "5024a220-b4ee-40fa-b604-7383cae082e2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.014521735720336437, 0.014521735720336437)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss.item(),loss.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azb-_U_FqzAd"
      },
      "source": [
        "Building a model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "f5zr33MAqf36"
      },
      "outputs": [],
      "source": [
        "class ManualLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # self.b = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
        "    # self.w = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  \n",
        "  def forward(self,x):\n",
        "    return self.b + self.w * x\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNVBX2ECrwi8",
        "outputId": "c265853c-ed2b-44ca-c94d-224df932aefc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OrderedDict([('b', tensor([1.0235])), ('w', tensor([1.9690]))])\n"
          ]
        }
      ],
      "source": [
        "lr = 0.1\n",
        "\n",
        "# Step 0 - Initializes parameters \"b\" and \"w\" randomly\n",
        "torch.manual_seed(42)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = ManualLinearRegression().to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "# (now retrieved directly from the model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    model.train() # What is this?!?\n",
        "\n",
        "    # Step 1 - Computes model's predicted output - forward pass\n",
        "    # No more manual prediction!\n",
        "    yhat = model(x_train_tensor)\n",
        "    \n",
        "    # Step 2 - Computes the loss\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Step 4 - Updates parameters using gradients and\n",
        "    # the learning rate\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "# We can also inspect its parameters using its state_dict\n",
        "print(model.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVOfFV9Ir2RP"
      },
      "outputs": [],
      "source": [
        "class ManualLinearRegression(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    # self.b = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
        "    # self.w = nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float))\n",
        "    self.linear = nn.Linear(1, 1)\n",
        "\n",
        "  \n",
        "  def forward(self,x):\n",
        "    # return self.b + self.w * x\n",
        "    return self.linear(x)\n",
        "  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKN5W0_p4XMk",
        "outputId": "50f5815d-e33c-4a70-e8fb-d6606060013f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (layer1): Linear(in_features=3, out_features=5, bias=True)\n",
              "  (layer2): Linear(in_features=5, out_features=1, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "# Building the model from the figure above\n",
        "model = nn.Sequential()\n",
        "model.add_module('layer1', nn.Linear(3, 5))\n",
        "model.add_module('layer2', nn.Linear(5, 1))\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svoBs3pu5rZT"
      },
      "source": [
        "## Template codes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "3gqKQcaG4Xkv",
        "outputId": "9630d128-1c8b-4c9b-a124-339e16069fc8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing data_preparation/v0.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile data_preparation/v0.py\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# Our data was in Numpy arrays, but we need to transform them\n",
        "# into PyTorch's Tensors and then we send them to the\n",
        "# chosen device\n",
        "x_train_tensor = torch.as_tensor(x_train).float().to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).float().to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "en5MmmyK7Hrg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing model_configuration/v0.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_configuration/v0.py\n",
        "\n",
        "# This is redundant now, but it won't be when we introduce\n",
        "# Datasets...\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# Sets learning rate - this is \"eta\" ~ the \"n\"-like Greek letter\n",
        "lr = 0.1\n",
        "\n",
        "torch.manual_seed(42)\n",
        "# Now we can create a model and send it at once to the device\n",
        "model = nn.Sequential(nn.Linear(1, 1)).to(device)\n",
        "\n",
        "# Defines a SGD optimizer to update the parameters \n",
        "# (now retrieved directly from the model)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "\n",
        "# Defines a MSE loss function\n",
        "loss_fn = nn.MSELoss(reduction='mean')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zbhg6YUo7UE-"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing model_training/v0.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile model_training/v0.py\n",
        "\n",
        "# Defines number of epochs\n",
        "n_epochs = 1000\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # Sets model to TRAIN mode\n",
        "    model.train()\n",
        "\n",
        "    # Step 1 - Computes model's predicted output - forward pass\n",
        "    yhat = model(x_train_tensor)\n",
        "    \n",
        "    # Step 2 - Computes the loss\n",
        "    loss = loss_fn(yhat, y_train_tensor)\n",
        "\n",
        "    # Step 3 - Computes gradients for both \"b\" and \"w\" parameters\n",
        "    loss.backward()\n",
        "    \n",
        "    # Step 4 - Updates parameters using gradients and \n",
        "    # the learning rate\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "name": "Chap_01.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 64-bit ('3.8.13')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
