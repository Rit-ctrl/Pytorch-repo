{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.23.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.2/31.2 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Downloading torch-1.12.0-cp38-cp38-manylinux1_x86_64.whl (776.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m776.3/776.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.13.0-cp38-cp38-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m104.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchtext\n",
      "  Downloading torchtext-0.13.0-cp38-cp38-manylinux1_x86_64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m108.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting torchviz\n",
      "  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorboard\n",
      "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m138.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting librosa\n",
      "  Downloading librosa-0.9.2-py3-none-any.whl (214 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.3/214.3 kB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.34.4-py3-none-any.whl (944 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m944.1/944.1 kB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m119.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (3.0.9)\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 2)) (2.8.2)\n",
      "Collecting scipy>=1.3.2\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.0.0\n",
      "  Downloading joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.0/307.0 kB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: typing-extensions in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from torch->-r requirements.txt (line 5)) (4.3.0)\n",
      "Requirement already satisfied: requests in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from torchvision->-r requirements.txt (line 6)) (2.28.1)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.2.0-py3-none-any.whl (232 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.2/232.2 kB\u001b[0m \u001b[31m77.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m150.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m132.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting protobuf<3.20,>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m129.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=0.4\n",
      "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting grpcio>=1.24.3\n",
      "  Downloading grpcio-1.47.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m178.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 9)) (0.37.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from tensorboard->-r requirements.txt (line 9)) (63.2.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.9.1-py2.py3-none-any.whl (167 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.8/167.8 kB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.10 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from librosa->-r requirements.txt (line 11)) (5.1.1)\n",
      "Collecting soundfile>=0.10.2\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3-none-any.whl (21 kB)\n",
      "Collecting resampy>=0.2.2\n",
      "  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m167.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting numba>=0.45.1\n",
      "  Downloading numba-0.55.2-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m142.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting audioread>=2.1.9\n",
      "  Downloading audioread-2.1.9.tar.gz (377 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.5/377.5 kB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pooch>=1.0\n",
      "  Downloading pooch-1.6.0-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: nbconvert in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 12)) (6.5.0)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-7.7.1-py2.py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jupyter-console\n",
      "  Downloading jupyter_console-6.4.4-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: notebook in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 12)) (6.4.12)\n",
      "Requirement already satisfied: ipykernel in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jupyter->-r requirements.txt (line 12)) (6.15.1)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.3.1-py3-none-any.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.8/120.8 kB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 9)) (1.16.0)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard->-r requirements.txt (line 9)) (4.12.0)\n",
      "Collecting llvmlite<0.39,>=0.38.0rc1\n",
      "  Downloading llvmlite-0.38.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.22.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m137.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting appdirs>=1.3.0\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 6)) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 6)) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 6)) (1.26.10)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from requests->torchvision->-r requirements.txt (line 6)) (3.3)\n",
      "Requirement already satisfied: cffi>=1.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from soundfile>=0.10.2->librosa->-r requirements.txt (line 11)) (1.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 9)) (2.1.1)\n",
      "Requirement already satisfied: ipython>=7.23.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (8.4.0)\n",
      "Requirement already satisfied: traitlets>=5.1.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (5.3.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (23.2.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.6.2)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (6.2)\n",
      "Requirement already satisfied: psutil in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (5.9.1)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (0.1.3)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (7.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipykernel->jupyter->-r requirements.txt (line 12)) (1.5.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipywidgets->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Collecting jupyterlab-widgets>=1.0.0\n",
      "  Downloading jupyterlab_widgets-1.1.1-py3-none-any.whl (245 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.3/245.3 kB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting widgetsnbextension~=3.6.0\n",
      "  Downloading widgetsnbextension-3.6.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m131.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pygments in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (2.12.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jupyter-console->jupyter->-r requirements.txt (line 12)) (3.0.30)\n",
      "Requirement already satisfied: jupyter-core>=4.7 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.11.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.8.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (4.11.1)\n",
      "Requirement already satisfied: defusedxml in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.7.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.5.0)\n",
      "Requirement already satisfied: jinja2>=3.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (3.1.2)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.6.6)\n",
      "Requirement already satisfied: nbformat>=5.1 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (5.4.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.4)\n",
      "Requirement already satisfied: bleach in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (5.0.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Requirement already satisfied: tinycss2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbconvert->jupyter->-r requirements.txt (line 12)) (1.1.1)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (1.8.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (21.3.0)\n",
      "Requirement already satisfied: prometheus-client in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.14.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from notebook->jupyter->-r requirements.txt (line 12)) (0.15.0)\n",
      "Collecting qtpy>=2.0.1\n",
      "  Downloading QtPy-2.1.0-py3-none-any.whl (68 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.2/68.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pycparser in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa->-r requirements.txt (line 11)) (2.21)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->-r requirements.txt (line 9)) (3.8.1)\n",
      "Requirement already satisfied: stack-data in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.3.0)\n",
      "Requirement already satisfied: pickleshare in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.18.1)\n",
      "Requirement already satisfied: backcall in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (4.8.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (4.7.2)\n",
      "Requirement already satisfied: fastjsonschema in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (2.16.1)\n",
      "Requirement already satisfied: wcwidth in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->jupyter-console->jupyter->-r requirements.txt (line 12)) (0.2.5)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.5/151.5 kB\u001b[0m \u001b[31m30.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: ptyprocess in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from terminado>=0.8.3->notebook->jupyter->-r requirements.txt (line 12)) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from argon2-cffi->notebook->jupyter->-r requirements.txt (line 12)) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from beautifulsoup4->nbconvert->jupyter->-r requirements.txt (line 12)) (2.3.2.post1)\n",
      "Requirement already satisfied: webencodings in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from bleach->nbconvert->jupyter->-r requirements.txt (line 12)) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (21.4.0)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat>=5.1->nbconvert->jupyter->-r requirements.txt (line 12)) (5.8.0)\n",
      "Requirement already satisfied: executing in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /home/gitpod/.pyenv/versions/3.8.13/lib/python3.8/site-packages (from stack-data->ipython>=7.23.1->ipykernel->jupyter->-r requirements.txt (line 12)) (0.2.2)\n",
      "Building wheels for collected packages: torchviz, audioread\n",
      "  Building wheel for torchviz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=fdd42577bc82ce72b91784c58cb779fbff8e4e2e63c81af27baac1cdd460c963\n",
      "  Stored in directory: /home/gitpod/.cache/pip/wheels/05/7d/1b/8306781244e42ede119edbb053bdcda1c1f424ca226165a417\n",
      "  Building wheel for audioread (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for audioread: filename=audioread-2.1.9-py3-none-any.whl size=23154 sha256=e8179e6c6e4694ce162669d60d50a645283e6e01539720e4a82150e844a7229f\n",
      "  Stored in directory: /home/gitpod/.cache/pip/wheels/49/5a/e4/df590783499a992a88de6c0898991d1167453a3196d0d1eeb7\n",
      "Successfully built torchviz audioread\n",
      "Installing collected packages: tensorboard-plugin-wit, pyasn1, audioread, appdirs, werkzeug, tqdm, torch, threadpoolctl, tensorboard-data-server, rsa, pyasn1-modules, protobuf, pillow, oauthlib, numpy, llvmlite, kiwisolver, jupyterlab-widgets, joblib, grpcio, graphviz, fonttools, cycler, cachetools, absl-py, torchviz, torchvision, torchtext, soundfile, scipy, requests-oauthlib, qtpy, pooch, opencv-python, numba, matplotlib, markdown, google-auth, scikit-learn, resampy, google-auth-oauthlib, tensorboard, librosa, qtconsole, jupyter-console, widgetsnbextension, ipywidgets, jupyter\n",
      "Successfully installed absl-py-1.2.0 appdirs-1.4.4 audioread-2.1.9 cachetools-5.2.0 cycler-0.11.0 fonttools-4.34.4 google-auth-2.9.1 google-auth-oauthlib-0.4.6 graphviz-0.20.1 grpcio-1.47.0 ipywidgets-7.7.1 joblib-1.1.0 jupyter-1.0.0 jupyter-console-6.4.4 jupyterlab-widgets-1.1.1 kiwisolver-1.4.4 librosa-0.9.2 llvmlite-0.38.1 markdown-3.4.1 matplotlib-3.5.2 numba-0.55.2 numpy-1.22.4 oauthlib-3.2.0 opencv-python-4.6.0.66 pillow-9.2.0 pooch-1.6.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 qtconsole-5.3.1 qtpy-2.1.0 requests-oauthlib-1.3.1 resampy-0.3.1 rsa-4.9 scikit-learn-1.1.1 scipy-1.8.1 soundfile-0.10.3.post1 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 threadpoolctl-3.1.0 torch-1.12.0 torchtext-0.13.0 torchvision-0.13.0 torchviz-0.0.2 tqdm-4.64.0 werkzeug-2.2.0 widgetsnbextension-3.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_generation/simple_linear_regression.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_step(model,loss_fn,optimizer):\n",
    "\n",
    "    def perform_train_step(x,y):\n",
    "        # set to train mode\n",
    "        model.train()\n",
    "\n",
    "        yhat = model(x)\n",
    "\n",
    "        loss = loss_fn(yhat,y)\n",
    "        #backprop\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v0.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model config v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_configuration/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v1.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr = lr)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "train_step = make_train_step(model,loss_fn,optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.make_train_step.<locals>.perform_train_step(x, y)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rewrite model_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_training/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v1.py\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    loss = train_step(x_train_tensor,y_train_tensor)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.9690]])), ('0.bias', tensor([1.0235]))])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self,x_tensor,y_tensor):\n",
    "        self.x = x_tensor\n",
    "        self.y = y_tensor\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index],self.y[index])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.as_tensor(x_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "train_data = CustomDataset(x_train_tensor,y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0.7713]), tensor([2.4745]))\n"
     ]
    }
   ],
   "source": [
    "# TensorDataset class\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor,y_train_tensor)\n",
    "print(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset = train_data,batch_size=16,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.2809],\n",
       "         [0.3253],\n",
       "         [0.1560],\n",
       "         [0.5924],\n",
       "         [0.0651],\n",
       "         [0.8872],\n",
       "         [0.4938],\n",
       "         [0.0055],\n",
       "         [0.1409],\n",
       "         [0.0885],\n",
       "         [0.1849],\n",
       "         [0.7290],\n",
       "         [0.8662],\n",
       "         [0.3117],\n",
       "         [0.6842],\n",
       "         [0.1987]]),\n",
       " tensor([[1.5846],\n",
       "         [1.8057],\n",
       "         [1.2901],\n",
       "         [2.1687],\n",
       "         [1.1559],\n",
       "         [2.8708],\n",
       "         [1.9060],\n",
       "         [1.0632],\n",
       "         [1.1211],\n",
       "         [1.0708],\n",
       "         [1.5888],\n",
       "         [2.4927],\n",
       "         [2.6805],\n",
       "         [1.7637],\n",
       "         [2.3492],\n",
       "         [1.2654]])]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refactor the training procedure\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_preparation/v1.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v1.py\n",
    "\n",
    "x_train_tensor = torch.as_tensor(x_train).float()\n",
    "y_train_tensor = torch.as_tensor(y_train).float()\n",
    "\n",
    "train_data = TensorDataset(x_train_tensor,y_train_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size = 16,shuffle=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v1.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v2.py\n",
    "\n",
    "n_epochs = 1000\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    mini_batch_losses = []\n",
    "    for x_batch,y_batch in train_loader:\n",
    "\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = train_step(x_batch,y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.9696]])), ('0.bias', tensor([1.0243]))])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mini_batch(device,data_loader,step):\n",
    "    mini_batch_losses = []\n",
    "    for x_batch,y_batch in data_loader:\n",
    "\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        mini_batch_loss = step(x_batch,y_batch)\n",
    "        mini_batch_losses.append(mini_batch_loss)\n",
    "\n",
    "    loss = np.mean(mini_batch_losses)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v3.py\n",
    "\n",
    " # Defines number of epochs\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    " # inner loop\n",
    "    loss = mini_batch(device, train_loader, train_step)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.9696]])), ('0.bias', tensor([1.0260]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data_preparation/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data_preparation/v2.py\n",
    "\n",
    "from idna import valid_label_length\n",
    "\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "x_tensor = torch.as_tensor(x).float()\n",
    "y_tensor = torch.as_tensor(y).float()\n",
    "\n",
    "dataset = TensorDataset(x_tensor,y_tensor)\n",
    "\n",
    "ratio = 0.8\n",
    "n_total = len(dataset)\n",
    "n_train = int(ratio * n_total)\n",
    "n_val = n_total - n_train\n",
    "\n",
    "train_data,val_data = random_split(dataset,[n_train,n_val])\n",
    "\n",
    "train_loader = DataLoader(dataset = train_data,batch_size = 16, shuffle = True)\n",
    "\n",
    "val_loader = DataLoader(dataset = val_data,batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_val_step(model,loss_fn):\n",
    "\n",
    "    def perform_val_step(x,y):\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat,y)\n",
    "\n",
    "        return loss.item()\n",
    "    \n",
    "    return perform_val_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_configuration/v2.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v2.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr = lr)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction = 'mean')\n",
    "\n",
    "train_step = make_train_step(model,loss_fn,optimizer)\n",
    "\n",
    "val_step = make_val_step(model,loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v4.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v4.py\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    loss = mini_batch(device,train_loader,train_step)\n",
    "    losses.append(loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device,val_loader,val_step)\n",
    "        val_losses.append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.9599]])), ('0.bias', tensor([1.0151]))])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting losses using Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 2819), started 0:05:20 ago. (Use '!kill 2819' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f79602bd335d4907\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f79602bd335d4907\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/Pytorch-repo/Pytorch-step-by-step/Chap_02.ipynb Cell 47\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Britctrl-pytorchrepo-ktfenmn9pud/workspace/Pytorch-repo/Pytorch-step-by-step/Chap_02.ipynb#ch0000049vscode-remote?line=0'>1</a>\u001b[0m writer\u001b[39m.\u001b[39;49madd_graph(model)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torch/utils/tensorboard/writer.py:840\u001b[0m, in \u001b[0;36mSummaryWriter.add_graph\u001b[0;34m(self, model, input_to_model, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    836\u001b[0m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_log_api_usage_once(\u001b[39m\"\u001b[39m\u001b[39mtensorboard.logging.add_graph\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(model, \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    838\u001b[0m     \u001b[39m# A valid PyTorch model should have a 'forward' method\u001b[39;00m\n\u001b[1;32m    839\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_file_writer()\u001b[39m.\u001b[39madd_graph(\n\u001b[0;32m--> 840\u001b[0m         graph(model, input_to_model, verbose, use_strict_trace)\n\u001b[1;32m    841\u001b[0m     )\n\u001b[1;32m    842\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     \u001b[39m# Caffe2 models do not have the 'forward' method\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mcaffe2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mproto\u001b[39;00m \u001b[39mimport\u001b[39;00m caffe2_pb2\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torch/utils/tensorboard/_pytorch_graph.py:338\u001b[0m, in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose, use_strict_trace)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mselect_model_mode_for_export(\n\u001b[1;32m    335\u001b[0m     model, torch\u001b[39m.\u001b[39monnx\u001b[39m.\u001b[39mTrainingMode\u001b[39m.\u001b[39mEVAL\n\u001b[1;32m    336\u001b[0m ):  \u001b[39m# TODO: move outside of torch.onnx?\u001b[39;00m\n\u001b[1;32m    337\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 338\u001b[0m         trace \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mjit\u001b[39m.\u001b[39;49mtrace(model, args, strict\u001b[39m=\u001b[39;49muse_strict_trace)\n\u001b[1;32m    339\u001b[0m         graph \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mgraph\n\u001b[1;32m    340\u001b[0m         torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_jit_pass_inline(graph)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torch/jit/_trace.py:750\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[39mreturn\u001b[39;00m func\n\u001b[1;32m    749\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(func, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule):\n\u001b[0;32m--> 750\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    751\u001b[0m         func,\n\u001b[1;32m    752\u001b[0m         {\u001b[39m\"\u001b[39;49m\u001b[39mforward\u001b[39;49m\u001b[39m\"\u001b[39;49m: example_inputs},\n\u001b[1;32m    753\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    754\u001b[0m         check_trace,\n\u001b[1;32m    755\u001b[0m         wrap_check_inputs(check_inputs),\n\u001b[1;32m    756\u001b[0m         check_tolerance,\n\u001b[1;32m    757\u001b[0m         strict,\n\u001b[1;32m    758\u001b[0m         _force_outplace,\n\u001b[1;32m    759\u001b[0m         _module_class,\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    762\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    763\u001b[0m     \u001b[39mhasattr\u001b[39m(func, \u001b[39m\"\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    764\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m, torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule)\n\u001b[1;32m    765\u001b[0m     \u001b[39mand\u001b[39;00m func\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m ):\n\u001b[1;32m    767\u001b[0m     \u001b[39mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    768\u001b[0m         func\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m,\n\u001b[1;32m    769\u001b[0m         {\u001b[39m\"\u001b[39m\u001b[39mforward\u001b[39m\u001b[39m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m         _module_class,\n\u001b[1;32m    777\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torch/jit/_trace.py:965\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    962\u001b[0m     func \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(mod, method_name)\n\u001b[1;32m    963\u001b[0m     argument_names \u001b[39m=\u001b[39m get_callable_argument_names(func)\n\u001b[0;32m--> 965\u001b[0m example_inputs \u001b[39m=\u001b[39m make_tuple(example_inputs)\n\u001b[1;32m    967\u001b[0m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_create_method_from_trace(\n\u001b[1;32m    968\u001b[0m     method_name,\n\u001b[1;32m    969\u001b[0m     func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    974\u001b[0m     argument_names,\n\u001b[1;32m    975\u001b[0m )\n\u001b[1;32m    976\u001b[0m check_trace_method \u001b[39m=\u001b[39m module\u001b[39m.\u001b[39m_c\u001b[39m.\u001b[39m_get_method(method_name)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/torch/jit/_trace.py:558\u001b[0m, in \u001b[0;36mmake_tuple\u001b[0;34m(example_inputs)\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[39m# done primarily so that weird iterables fail here and not pybind11 code\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(example_inputs, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m--> 558\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39;49m(example_inputs)\n\u001b[1;32m    559\u001b[0m \u001b[39mreturn\u001b[39;00m example_inputs\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_x, dummy_y = next(iter(train_loader))\n",
    "writer.add_graph(model, dummy_x.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_scalars(main_tag='loss',\n",
    "tag_scalar_dict={'training':loss,\n",
    "                'validation':val_loss},\n",
    "                global_step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_configuration/v3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_configuration/v3.py\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "lr = 0.1\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "model = nn.Sequential(nn.Linear(1,1)).to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(),lr=lr)\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction = 'mean')\n",
    "\n",
    "train_step = make_train_step(model, loss_fn, optimizer)\n",
    "val_step = make_val_step(model, loss_fn)\n",
    "\n",
    "writer = SummaryWriter('runs/simple_linear_regression')\n",
    "\n",
    "# Fetches a single mini-batch so we can use add_graph\n",
    "x_dummy, y_dummy = next(iter(train_loader))\n",
    "writer.add_graph(model, x_dummy.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model_training/v5.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_training/v5.py\n",
    "\n",
    "n_epochs = 200\n",
    "\n",
    "losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    loss = mini_batch(device,train_loader,train_step)\n",
    "    losses.append(loss)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_loss = mini_batch(device,val_loader,val_step)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    writer.add_scalars(main_tag='loss',\n",
    "                       tag_scalar_dict=\n",
    "                       {'training':loss,\n",
    "                       'validation':val_loss\n",
    "                       },\n",
    "                       global_step=epoch)\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.9583]])), ('0.bias', tensor([1.0099]))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = {\n",
    "    'epoch' : n_epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict':optimizer.state_dict(),\n",
    "    'loss':losses,\n",
    "    'val_loss':val_losses\n",
    "}\n",
    "\n",
    "torch.save(checkpoint,'model_checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i data_preparation/v2.py\n",
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[0.7645]])), ('0.bias', tensor([0.8300]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "saved_epoch = checkpoint['epoch']\n",
    "saved_losses = checkpoint['loss']\n",
    "saved_val_losses = checkpoint['val_loss']\n",
    "\n",
    "model.train() # use train if you want to resume training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[1.9583]])), ('0.bias', tensor([1.0099]))])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_training/v5.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9583]])), ('0.bias', tensor([1.0099]))])\n"
     ]
    }
   ],
   "source": [
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i model_configuration/v3.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('0.weight', tensor([[1.9583]])), ('0.bias', tensor([1.0099]))])\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4015],\n",
       "        [1.6757],\n",
       "        [2.1261]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_inputs = torch.tensor([[.20], [.34], [.57]])\n",
    "model.eval() # always use EVAL for fully trained models!\n",
    "model(new_inputs.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit ('3.8.13')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "110cc1dee26208153f2972f08a2ad52b6a56238dc66d48e87fb757ef2996db56"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
